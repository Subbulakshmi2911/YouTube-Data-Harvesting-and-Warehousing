{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timedelta\n",
    "import json \n",
    "import isodate\n",
    "import streamlit as st\n",
    "import uuid\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"AIzaSyAMW1l2tFN7r00v56cS0WLL6_uEHKCoPVs\"\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get channel id\n",
    "def get_channel_info(channel_id):\n",
    "\n",
    "    response = youtube.channels().list(\n",
    "        id=channel_id,\n",
    "        part='snippet,statistics,contentDetails'\n",
    "    ).execute()\n",
    "\n",
    "    for i in response['items']:\n",
    "        data=dict(Channel_Names=i['snippet']['title'],\n",
    "                  channel_Id=i['id'],\n",
    "                  subscribers=i['statistics']['subscriberCount'],\n",
    "                  Views=i['statistics']['viewCount'],\n",
    "                  Total_Videos=i['statistics']['videoCount'],\n",
    "                  Chennal_Description=i['snippet']['description'],\n",
    "                  Playlist_Id=i['contentDetails']['relatedPlaylists']['uploads']\n",
    "                  )\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_videos_ids(channel_id):\n",
    "    video_ids = []\n",
    "    \n",
    "    # Fetch the upload playlist ID for the channel\n",
    "    response = youtube.channels().list(\n",
    "        id=channel_id,\n",
    "        part='contentDetails'\n",
    "    ).execute()\n",
    "\n",
    "    playlist_id = response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    next_page_token = None\n",
    "\n",
    "    # Loop to retrieve video IDs from the upload playlist\n",
    "    while True:\n",
    "        response1 = youtube.playlistItems().list(\n",
    "            part='snippet',\n",
    "            playlistId=playlist_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        for item in response1['items']:\n",
    "            video_ids.append(item['snippet']['resourceId']['videoId'])\n",
    "\n",
    "        next_page_token = response1.get('nextPageToken')\n",
    "\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return video_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get video ids\n",
    "def get_videos_ids(channel_id):\n",
    "\n",
    "      video_ids=[]\n",
    "      response = youtube.channels().list(\n",
    "              id=channel_id,\n",
    "              part='contentDetails'\n",
    "          ).execute()\n",
    "\n",
    "      Playlist_Id=response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "      next_page_token=None\n",
    "\n",
    "      while True:\n",
    "          response1=youtube.playlistItems().list(\n",
    "              part='snippet',\n",
    "              playlistId=Playlist_Id,maxResults=50,\n",
    "              pageToken=next_page_token).execute()\n",
    "\n",
    "\n",
    "          for i in range(len(response1['items'])):\n",
    "                  video_ids.append(response1['items'][i]['snippet']['resourceId']['videoId'])\n",
    "          next_page_token=response1.get('nextPageToken')\n",
    "\n",
    "          if next_page_token is None:\n",
    "            break\n",
    "      return video_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET VIDEO INFORMATION\n",
    "def get_video_info(video_ids):\n",
    "  video_data=[]\n",
    "  try:\n",
    "      for video_id in video_ids:\n",
    "\n",
    "          response = youtube.videos().list(part='snippet,ContentDetails,statistics',\n",
    "                                        id=video_id).execute()\n",
    "          for i in response['items']:\n",
    "            data=dict(Channel_Names=i['snippet']['channelTitle'],\n",
    "                      channel_Id=i['snippet']['channelId'],\n",
    "                      Video_Id=i['id'],\n",
    "                      Title=i['snippet']['title'],\n",
    "                      Tags=i.get('tags'),\n",
    "                      Thumbnail=i['snippet']['thumbnails'],\n",
    "                      Description=i.get('description'),\n",
    "                      Published_Date=i['snippet']['publishedAt'],\n",
    "                      Duration=i['contentDetails']['duration'],\n",
    "                      views=i.get('viewCount'),\n",
    "                      Comments=i.get('commentCount'),\n",
    "                      Favorite_Count=i['statistics']['favoriteCount'],\n",
    "                      Definition=i['contentDetails']['definition'],\n",
    "                      Caption_Status=i['contentDetails']['caption'])\n",
    "            video_data.append(data)\n",
    "  except:\n",
    "        pass\n",
    "  return video_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addtion code for video info\n",
    "def get_video_info(video_ids):\n",
    "    video_data = []\n",
    "    try:\n",
    "        response = youtube.videos().list(\n",
    "            part='snippet,contentDetails,statistics',\n",
    "            id=','.join(video_ids)  # Fetch all video IDs in a single API call\n",
    "        ).execute()\n",
    "\n",
    "        for item in response.get('items', []):\n",
    "            data = {\n",
    "                'Channel_Names': item['snippet']['channelTitle'],\n",
    "                'channel_Id': item['snippet']['channelId'],\n",
    "                'Video_Id': item['id'],\n",
    "                'Title': item['snippet']['title'],\n",
    "                'Tags': item.get('tags'),\n",
    "                'Thumbnail': item['snippet']['thumbnails'],\n",
    "                'Description': item.get('description'),\n",
    "                'Published_Date': item['snippet']['publishedAt'],\n",
    "                'Duration': item['contentDetails']['duration'],\n",
    "                'views': item['statistics'].get('viewCount'),\n",
    "                'Comments': item['statistics'].get('commentCount'),\n",
    "                'Favorite_Count': item['statistics'].get('favoriteCount'),\n",
    "                'Definition': item['contentDetails']['definition'],\n",
    "                'Caption_Status': item['contentDetails']['caption']\n",
    "            }\n",
    "            video_data.append(data)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")  # Better error handling\n",
    "    return video_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get comment info\n",
    "def get_comment_info(video_ids):\n",
    "    comment_data = []\n",
    "    try:\n",
    "        for video_id in video_ids:\n",
    "            response = youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=50,\n",
    "                key=api_key\n",
    "            ).execute()\n",
    "\n",
    "            for item in response.get('items', []):\n",
    "                snippet = item.get('snippet', {}).get('topLevelComment', {}).get('snippet', {})\n",
    "                data = {\n",
    "                    'comment_Id': snippet.get('id'),\n",
    "                    'Video_id': snippet.get('videoId'),\n",
    "                    'Comment_Text': snippet.get('textDisplay'),\n",
    "                    'Comment_Author': snippet.get('authorDisplayName'),\n",
    "                    'Comment_Published': snippet.get('publishedAt')\n",
    "                }\n",
    "                comment_data.append(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "    return comment_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_comments(video_id):\n",
    "    try:\n",
    "        response = youtube.commentThreads().list(\n",
    "            part='snippet',\n",
    "            videoId=video_id,\n",
    "            maxResults=50\n",
    "        ).execute()\n",
    "\n",
    "        comments = []\n",
    "        for item in response['items']:\n",
    "            snippet = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            data = {\n",
    "                    'comment_Id': snippet.get('id'),\n",
    "                    'Video_id': snippet.get('videoId'),\n",
    "                    'Comment_Text': snippet.get('textDisplay'),\n",
    "                    'Comment_Author': snippet.get('authorDisplayName'),\n",
    "                    'Comment_Published': snippet.get('publishedAt')\n",
    "                }\n",
    "            comments.append(data)\n",
    "\n",
    "        return comments\n",
    "\n",
    "    except HttpError as e:\n",
    "        error_message = e._get_reason()\n",
    "        if 'commentsDisabled' in error_message:\n",
    "            print(f\"Comments are disabled for video ID: {video_id}\")\n",
    "        elif 'video not found' in error_message:\n",
    "            print(f\"Video not found for video ID: {video_id}\")\n",
    "        else:\n",
    "            print(f\"An error occurred: {error_message}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get playlist_details\n",
    "def get_playlist_details(channal_id):\n",
    "  All_data=[]\n",
    "  next_page_token=None\n",
    "  while True:\n",
    "    response=youtube.playlists().list(\n",
    "        part='snippet,contentDetails',\n",
    "        channelId=channal_id,\n",
    "        maxResults=50,\n",
    "        pageToken=next_page_token).execute()\n",
    "    for i in response['items']:\n",
    "      data=dict(Playlist_Id=i['id'],\n",
    "              Title=i['snippet']['title'],\n",
    "                Channel_Id=i['snippet']['channelId'],\n",
    "                Channel_Name=i['snippet']['channelTitle'],\n",
    "                PublishedAt=i['snippet']['publishedAt'],\n",
    "                Video_Count=i['contentDetails']['itemCount'])\n",
    "      All_data.append(data)\n",
    "    next_page_token=response.get('nextPageToken')\n",
    "    if next_page_token is None:\n",
    "     break\n",
    "\n",
    "  return All_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: <HttpError 400 when requesting https://youtube.googleapis.com/youtube/v3/videos?part=snippet%2CcontentDetails%2Cstatistics&id=Iwgj6T8OPT8%2CexjfLOH9IY4%2CKLBdabZ_i6Y%2CSwCkexMKwA8%2CcyvDkpLh248%2C9mVks4IR-xQ%2CBur4Rjair4k%2CjsPPJMmfyjI%2CMeXe35xd9_0%2CsQ5mdm-N_Xo%2CW1H6RsFZ6uk%2CofWyFqrow3M%2CjPz-gpn_rm4%2Cf_T-lN3zqK8%2CiNRedRELPBw%2CR-kO5ZZY47w%2CBrX_Vh37a4k%2CpAwkGe_Qe8o%2Cy577gMG8u3o%2CpgNE6381MCo%2CLs45ehnjW6Y%2CHH1d16aeDFE%2C6oAELHNH2zY%2CsPV9X0x6Oeg%2CaxdWCEk65RI%2CqiVwEtYtTjo%2CSqsP5wCqLXc%2CULVFetwMeBI%2CU2A4nYw_rR0%2C8pK_njBtNdg%2CltRTXrbpXYM%2Cont6nyjgYVQ%2CA88dvfcICrU%2C84lPUHg0sFo%2CiIsZzOeTn-8%2Coftn64D9LsA%2CLSPBYoqqcPE%2CTU-t9_C7QjU%2C_qzWsQG2izU%2ClET0dZDZnqc%2CdD6mEgyEGAk%2CvHiQoPJhfrs%2C9hnuA4imiAE%2CgBwEJ-2DPQc%2CBdoCNd_5qEs%2Cfxp5Nism024%2CMW5dLYsi-l4%2CfR9QylOAwnY%2COTLavrhbNCg%2C9_S1VajqoDM%2CHMAY9gkvwFo%2C_rQzHuApgXs%2CbosRfQ0ew00%2CvwpxrKowgc8%2CaENAaJ2ysuQ%2CYBgc3oruiQU%2CGv17f9XkJWI%2CJaxG2A4T8GI%2CU5kd9HmM94U%2CKYA9w0BWQcs%2CvAEsq9NGxAI%2CIAZcAwG_Mhg%2Cj3RNC1iYOqU%2CqdpN6J2n3pY%2ClwkffcQ2Zt0%2C9nEINER6kJM%2CPnRHcL_-iHA%2CETkFs-hYEQc%2C-FVq8EVJTvk%2C0iKRy2zGW8o%2C6XFUXIJf-As%2CJdbd9wwYAp4%2CeNfU9Z5yGyM%2C0T43gMWV8qM%2CPfFmOIsXWCU%2CUvAxsaNE2BI%2CHX-hMkKf5DA%2CnBEoB0nEIhw%2CSI0NA6k-lME%2Ch4B3Psww4vo%2CuKnHTsFXWTU%2COYW2HKrmfek&key=AIzaSyAMW1l2tFN7r00v56cS0WLL6_uEHKCoPVs&alt=json returned \"The request specifies an invalid filter parameter.\". Details: \"[{'message': 'The request specifies an invalid filter parameter.', 'domain': 'youtube.parameter', 'reason': 'invalidFilters', 'location': 'parameters.', 'locationType': 'other'}]\">\n",
      "An error occurred: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=ltRTXrbpXYM&maxResults=50&key=AIzaSyAMW1l2tFN7r00v56cS0WLL6_uEHKCoPVs&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.', 'domain': 'youtube.commentThread', 'reason': 'commentsDisabled', 'location': 'videoId', 'locationType': 'parameter'}]\">\n"
     ]
    }
   ],
   "source": [
    "def channel_details(channel_id):\n",
    "  channel_details=get_channel_info(channel_id)\n",
    "  playlist_details=get_playlist_details(channel_id)\n",
    "  video_ids=get_videos_ids(channel_id)\n",
    "  video_details=get_video_info(video_ids)\n",
    "  comment_details=get_comment_info(video_ids)\n",
    "\n",
    "insert=channel_details('UCs0zfLJmh564g_f1qDQIT0g')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID: 9mVks4IR-xQ\n",
      "Title: Naa erikkara melirunthu song #whatsappstatus #sad #lovefailure  @maimozhi\n",
      "Channel Name: Mai Mozhi\n",
      "Channel ID: UCs0zfLJmh564g_f1qDQIT0g\n",
      "Published Date: 2023-12-09T03:21:59Z\n",
      "Description: No description available.\n",
      "Duration: PT28S\n",
      "Views: 80\n",
      "Comments: 0\n",
      "Favorite Count: 0\n",
      "Definition: hd\n",
      "Caption Status: false\n",
      "Tags: No tags available.\n",
      "Thumbnail URL: https://i.ytimg.com/vi/9mVks4IR-xQ/default.jpg\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# additional code for video info\n",
    "def display_video_info(video_data):\n",
    "    for video in video_data:\n",
    "        print(\"Video ID:\", video['Video_Id'])\n",
    "        print(\"Title:\", video['Title'])\n",
    "        print(\"Channel Name:\", video['Channel_Names'])\n",
    "        print(\"Channel ID:\", video['channel_Id'])\n",
    "        print(\"Published Date:\", video['Published_Date'])\n",
    "        print(\"Description:\", video['Description'] or \"No description available.\")\n",
    "        print(\"Duration:\", video['Duration'])\n",
    "        print(\"Views:\", video['views'] or \"Data not available.\")\n",
    "        print(\"Comments:\", video['Comments'] or \"Data not available.\")\n",
    "        print(\"Favorite Count:\", video['Favorite_Count'] or \"Data not available.\")\n",
    "        print(\"Definition:\", video['Definition'])\n",
    "        print(\"Caption Status:\", video['Caption_Status'])\n",
    "        print(\"Tags:\", video['Tags'] or \"No tags available.\")\n",
    "        print(\"Thumbnail URL:\", video['Thumbnail'].get('default', {}).get('url', \"No thumbnail available.\"))\n",
    "        print(\"=\" * 40)  # Separator for clarity\n",
    "\n",
    "# Example usage\n",
    "video_ids = [\"9mVks4IR-xQ\", \"VBur4Rjair4k\"]  # Replace with actual video IDs\n",
    "video_data = get_video_info(video_ids)\n",
    "display_video_info(video_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: <HttpError 400 when requesting https://youtube.googleapis.com/youtube/v3/videos returned \"The request specifies an invalid filter parameter.\". Details: \"[{'message': 'The request specifies an invalid filter parameter.', 'domain': 'youtube.parameter', 'reason': 'invalidFilters', 'location': 'parameters.', 'locationType': 'other'}]\">\n",
      "An error occurred: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=YzJt3nsY9JQ&maxResults=50&key=AIzaSyAMW1l2tFN7r00v56cS0WLL6_uEHKCoPVs&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.', 'domain': 'youtube.commentThread', 'reason': 'commentsDisabled', 'location': 'videoId', 'locationType': 'parameter'}]\">\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "client=pymongo.MongoClient(\"mongodb://subbu:vembu@ac-hxu0gpw-shard-00-00.udikzhc.mongodb.net:27017,ac-hxu0gpw-shard-00-01.udikzhc.mongodb.net:27017,ac-hxu0gpw-shard-00-02.udikzhc.mongodb.net:27017/?ssl=true&replicaSet=atlas-bvhqgr-shard-0&authSource=admin&retryWrites=true&w=majority&appName=Cluster0\")\n",
    "\n",
    "db=client[\"Youtube_data\"]\n",
    "def channel_details(channel_id):\n",
    "  channel_details=get_channel_info(channel_id)\n",
    "  playlist_details=get_playlist_details(channel_id)\n",
    "  video_ids=get_videos_ids(channel_id)\n",
    "  video_details=get_video_info(video_ids)\n",
    "  comment_details=get_comment_info(video_ids)\n",
    "  collection=db[\"channel_details\"]\n",
    "  collection.insert_one({\"channel_information\":channel_details,\"playlist_information\":playlist_details,\"video_information\":video_details,\"comment_information\":comment_details})\n",
    "  return \"upload successfully\"\n",
    "\n",
    "insert=channel_details('UCHGktfcQq2BY_8tGPHwv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=client[\"Youtube_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel_Names</th>\n",
       "      <th>channel_Id</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>Views</th>\n",
       "      <th>Total_Videos</th>\n",
       "      <th>Chennal_Description</th>\n",
       "      <th>Playlist_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mai Mozhi</td>\n",
       "      <td>UCs0zfLJmh564g_f1qDQIT0g</td>\n",
       "      <td>85</td>\n",
       "      <td>22871</td>\n",
       "      <td>82</td>\n",
       "      <td>நம் மனம் கவர்ந்த பாடல் வரிகளுக்கு.... என்றென்ற...</td>\n",
       "      <td>UUs0zfLJmh564g_f1qDQIT0g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mai Mozhi</td>\n",
       "      <td>UCs0zfLJmh564g_f1qDQIT0g</td>\n",
       "      <td>88</td>\n",
       "      <td>23083</td>\n",
       "      <td>82</td>\n",
       "      <td>நம் மனம் கவர்ந்த பாடல் வரிகளுக்கு.... என்றென்ற...</td>\n",
       "      <td>UUs0zfLJmh564g_f1qDQIT0g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amit Thinks</td>\n",
       "      <td>UCgnr2Lkl1LZf0IOKRDAoJ2g</td>\n",
       "      <td>215000</td>\n",
       "      <td>63427710</td>\n",
       "      <td>2217</td>\n",
       "      <td>I am Amit Diwan, an entrepreneur who runs \"Ami...</td>\n",
       "      <td>UUgnr2Lkl1LZf0IOKRDAoJ2g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Madras Samayal</td>\n",
       "      <td>UCHGktfcQq2BY_8tGPHwvm7g</td>\n",
       "      <td>6120000</td>\n",
       "      <td>1590930811</td>\n",
       "      <td>838</td>\n",
       "      <td>Madras Samayal features traditional and modern...</td>\n",
       "      <td>UUHGktfcQq2BY_8tGPHwvm7g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Madras Samayal</td>\n",
       "      <td>UCHGktfcQq2BY_8tGPHwvm7g</td>\n",
       "      <td>6120000</td>\n",
       "      <td>1590930811</td>\n",
       "      <td>838</td>\n",
       "      <td>Madras Samayal features traditional and modern...</td>\n",
       "      <td>UUHGktfcQq2BY_8tGPHwvm7g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Madras Samayal</td>\n",
       "      <td>UCHGktfcQq2BY_8tGPHwvm7g</td>\n",
       "      <td>6120000</td>\n",
       "      <td>1590930811</td>\n",
       "      <td>838</td>\n",
       "      <td>Madras Samayal features traditional and modern...</td>\n",
       "      <td>UUHGktfcQq2BY_8tGPHwvm7g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Channel_Names                channel_Id subscribers       Views  \\\n",
       "0       Mai Mozhi  UCs0zfLJmh564g_f1qDQIT0g          85       22871   \n",
       "1       Mai Mozhi  UCs0zfLJmh564g_f1qDQIT0g          88       23083   \n",
       "2     Amit Thinks  UCgnr2Lkl1LZf0IOKRDAoJ2g      215000    63427710   \n",
       "3  Madras Samayal  UCHGktfcQq2BY_8tGPHwvm7g     6120000  1590930811   \n",
       "4  Madras Samayal  UCHGktfcQq2BY_8tGPHwvm7g     6120000  1590930811   \n",
       "5  Madras Samayal  UCHGktfcQq2BY_8tGPHwvm7g     6120000  1590930811   \n",
       "\n",
       "  Total_Videos                                Chennal_Description  \\\n",
       "0           82  நம் மனம் கவர்ந்த பாடல் வரிகளுக்கு.... என்றென்ற...   \n",
       "1           82  நம் மனம் கவர்ந்த பாடல் வரிகளுக்கு.... என்றென்ற...   \n",
       "2         2217  I am Amit Diwan, an entrepreneur who runs \"Ami...   \n",
       "3          838  Madras Samayal features traditional and modern...   \n",
       "4          838  Madras Samayal features traditional and modern...   \n",
       "5          838  Madras Samayal features traditional and modern...   \n",
       "\n",
       "                Playlist_Id  \n",
       "0  UUs0zfLJmh564g_f1qDQIT0g  \n",
       "1  UUs0zfLJmh564g_f1qDQIT0g  \n",
       "2  UUgnr2Lkl1LZf0IOKRDAoJ2g  \n",
       "3  UUHGktfcQq2BY_8tGPHwvm7g  \n",
       "4  UUHGktfcQq2BY_8tGPHwvm7g  \n",
       "5  UUHGktfcQq2BY_8tGPHwvm7g  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "single_channel_details = []\n",
    "coll1 = db[\"channel_details\"]\n",
    "for ch_data in coll1.find({}, {\"_id\": 0, \"channel_information\": 1}):\n",
    "        single_channel_details.append(ch_data[\"channel_information\"])\n",
    "df = pd.DataFrame(single_channel_details)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import isodate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def channels_table():\n",
    "def channels_table(channel_name):\n",
    "        mydb=mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        passwd='root',\n",
    "        database='youtube')\n",
    "\n",
    "        cursor=mydb.cursor()\n",
    "        drop_query = '''DROP TABLE IF EXISTS channels'''\n",
    "        cursor.execute(drop_query)\n",
    "        mydb.commit()\n",
    "\n",
    "\n",
    "        try:\n",
    "                create_query='''create table if not exists channels(Channel_Names varchar(100),\n",
    "                                                                channel_Id varchar(80) primary key,\n",
    "                                                                subscribers bigint,\n",
    "                                                                Views bigint,\n",
    "                                                                Total_Videos int,\n",
    "                                                                Chennal_Description text,\n",
    "                                                                Playlist_Id varchar(80))'''\n",
    "                cursor.execute(create_query)\n",
    "                mydb.commit()\n",
    "\n",
    "        except:\n",
    "                print(\"Channels table already created\")\n",
    "\n",
    "        single_channel_details= []\n",
    "        db=client[\"Youtube_data\"]\n",
    "        coll1=db[\"channel_details\"]\n",
    "        for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "                print(ch_data[\"channel_information\"])\n",
    "                single_channel_details.append(ch_data[\"channel_information\"])\n",
    "        df_single_channel= pd.DataFrame(single_channel_details)\n",
    "\n",
    "        for index,row in df_single_channel.iterrows():\n",
    "                insert_query='''insert into channels(Channel_Names,\n",
    "                                                        channel_Id,\n",
    "                                                        subscribers,\n",
    "                                                        Views,\n",
    "                                                        Total_Videos,\n",
    "                                                        Chennal_Description,\n",
    "                                                        Playlist_Id)\n",
    "                                                        \n",
    "                                                        values(%s,%s,%s,%s,%s,%s,%s)'''\n",
    "                values=(row['Channel_Names'],\n",
    "                        row['channel_Id'],\n",
    "                        row['subscribers'],\n",
    "                        row['Views'],\n",
    "                        row['Total_Videos'],\n",
    "                        row['Chennal_Description'],\n",
    "                        row['Playlist_Id'])\n",
    "\n",
    "                try:\n",
    "                        cursor.execute(insert_query,values)\n",
    "                        mydb.commit()\n",
    "\n",
    "                except:\n",
    "                        print(\"Channel values are already inserted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL database.\n",
      "Retrieved 6 channel(s) from MongoDB.\n",
      "Channel with ID UCs0zfLJmh564g_f1qDQIT0g already exists in the database.\n",
      "Channel with ID UCHGktfcQq2BY_8tGPHwvm7g already exists in the database.\n",
      "Channel with ID UCHGktfcQq2BY_8tGPHwvm7g already exists in the database.\n",
      "Data committed to the database successfully.\n",
      "Total records in channels table: 3\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def channels_table():\n",
    "    # Connect to MongoDB\n",
    "    client=pymongo.MongoClient(\"mongodb://subbu:vembu@ac-hxu0gpw-shard-00-00.udikzhc.mongodb.net:27017,ac-hxu0gpw-shard-00-01.udikzhc.mongodb.net:27017,ac-hxu0gpw-shard-00-02.udikzhc.mongodb.net:27017/?ssl=true&replicaSet=atlas-bvhqgr-shard-0&authSource=admin&retryWrites=true&w=majority&appName=Cluster0\")\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "\n",
    "    # Connect to the MySQL database\n",
    "    mydb = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        passwd='root',\n",
    "        database='youtube'\n",
    "    )\n",
    "\n",
    "    print(\"Connected to MySQL database.\")\n",
    "\n",
    "    try:\n",
    "        with mydb.cursor() as cursor:\n",
    "            # Drop the channels table if it exists\n",
    "            cursor.execute('DROP TABLE IF EXISTS channels')\n",
    "            mydb.commit()\n",
    "\n",
    "            # Create the channels table\n",
    "            create_query = '''CREATE TABLE IF NOT EXISTS channels (\n",
    "                                Channel_Names VARCHAR(100),\n",
    "                                channel_Id VARCHAR(80) PRIMARY KEY,\n",
    "                                subscribers BIGINT,\n",
    "                                Views BIGINT,\n",
    "                                Total_Videos INT,\n",
    "                                Chennal_Description\tTEXT,\n",
    "                                Playlist_Id VARCHAR(80)\n",
    "                             )'''\n",
    "            cursor.execute(create_query)\n",
    "            mydb.commit()\n",
    "\n",
    "            # Fetch channel details from MongoDB\n",
    "            single_channel_details = []\n",
    "            for ch_data in coll1.find({}, {\"_id\": 0, \"channel_information\": 1}):\n",
    "                single_channel_details.append(ch_data[\"channel_information\"])\n",
    "\n",
    "            # Debugging: Check number of records retrieved\n",
    "            print(f\"Retrieved {len(single_channel_details)} channel(s) from MongoDB.\")\n",
    "\n",
    "            # Convert to DataFrame\n",
    "            df_single_channel = pd.DataFrame(single_channel_details)\n",
    "\n",
    "            # Check if DataFrame is empty\n",
    "            if df_single_channel.empty:\n",
    "                print(\"No data to insert. DataFrame is empty.\")\n",
    "                return\n",
    "\n",
    "            # Insert data into the channels table\n",
    "            insert_query = '''INSERT INTO channels (Channel_Names, channel_Id, subscribers, Views, Total_Videos, Chennal_Description, Playlist_Id) \n",
    "                              VALUES (%s, %s, %s, %s, %s, %s, %s)'''\n",
    "            for index, row in df_single_channel.iterrows():\n",
    "                values = (row['Channel_Names'],\n",
    "                          row['channel_Id'],\n",
    "                          row['subscribers'],\n",
    "                          row['Views'],\n",
    "                          row['Total_Videos'],\n",
    "                          row['Chennal_Description'],\n",
    "                          row['Playlist_Id'])\n",
    "\n",
    "                try:\n",
    "                    cursor.execute(insert_query, values)\n",
    "                except mysql.connector.IntegrityError:\n",
    "                    print(f\"Channel with ID {row['channel_Id']} already exists in the database.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while inserting row {index}: {e}\")\n",
    "\n",
    "            # Commit the transaction after all insertions\n",
    "            mydb.commit()\n",
    "            print(\"Data committed to the database successfully.\")\n",
    "\n",
    "            # Verify if data was inserted\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM channels\")\n",
    "            count = cursor.fetchone()[0]\n",
    "            print(f\"Total records in channels table: {count}\")\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Database error: {err}\")\n",
    "    finally:\n",
    "        mydb.close()\n",
    "        client.close()\n",
    "\n",
    "# Example usage\n",
    "channels_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment table\n",
    "def comments_table(channel_name):\n",
    "    mydb = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        passwd='root',\n",
    "        database='youtube'\n",
    "    )\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    # Drop the table if it exists\n",
    "    drop_query = '''DROP TABLE IF EXISTS comments'''\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    # Create the comments table if it doesn't exist\n",
    "    create_query = '''CREATE TABLE IF NOT EXISTS comments(\n",
    "                        comment_Id VARCHAR(100) PRIMARY KEY,\n",
    "                        Video_id VARCHAR(50),\n",
    "                        Comment_Text TEXT,\n",
    "                        Comment_Author VARCHAR(150),\n",
    "                        Comment_Published TIMESTAMP\n",
    "                    )'''\n",
    "    cursor.execute(create_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    # Fetch comment information from MongoDB\n",
    "    single_channel_details = []\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for ch_data in coll1.find({}, {\"_id\": 0, \"comment_information\": 1}):\n",
    "        if \"comment_information\" in ch_data:\n",
    "            single_channel_details.append(ch_data[\"comment_information\"])\n",
    "\n",
    "    # Check if there's data to process\n",
    "    if single_channel_details:\n",
    "        df_single_channel = pd.DataFrame(single_channel_details[0])\n",
    "    else:\n",
    "        df_single_channel = pd.DataFrame()  # Handle empty data scenario\n",
    "\n",
    "    # Insert DataFrame rows into the MySQL table\n",
    "    insert_query = '''INSERT INTO comments(\n",
    "                        comment_Id,\n",
    "                        Video_id,\n",
    "                        Comment_Text,\n",
    "                        Comment_Author,\n",
    "                        Comment_Published\n",
    "                    ) VALUES (%s, %s, %s, %s, %s)'''\n",
    "\n",
    "    for index, row in df_single_channel.iterrows():\n",
    "        # If comment_Id is None, generate a unique UUID\n",
    "        comment_id = row.get('comment_Id') or str(uuid.uuid4())\n",
    "        \n",
    "        # Convert ISO 8601 timestamp to MySQL-compatible format (if not already in correct format)\n",
    "        try:\n",
    "            comment_published = isodate.parse_datetime(row.get('Comment_Published')).strftime('%Y-%m-%d %H:%M:%S') if row.get('Comment_Published') else None\n",
    "        except (ValueError, TypeError):\n",
    "            print(f\"Skipping invalid datetime value for comment_Id {comment_id}\")\n",
    "            continue\n",
    "\n",
    "        values = (\n",
    "            comment_id,\n",
    "            row.get('Video_id'),\n",
    "            row.get('Comment_Text'),\n",
    "            row.get('Comment_Author'),\n",
    "            comment_published  # Use the converted datetime value\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            cursor.execute(insert_query, values)\n",
    "            mydb.commit()\n",
    "        except mysql.connector.IntegrityError as ie:\n",
    "            print(f\"IntegrityError: Record with comment_Id {comment_id} already exists. Skipping.\")\n",
    "        except mysql.connector.DataError as de:\n",
    "            print(f\"DataError: {de}\")\n",
    "            print(f\"Problematic data: {values}\")\n",
    "            mydb.rollback()\n",
    "        except mysql.connector.Error as err:\n",
    "            print(f\"Error inserting data: {err}\")\n",
    "            mydb.rollback()\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videos_table(channel_name):\n",
    "\n",
    "    # Function to convert datetime from ISO 8601 to MySQL format\n",
    "    def convert_to_mysql_datetime(iso_datetime):\n",
    "        return datetime.strptime(iso_datetime, \"%Y-%m-%dT%H:%M:%SZ\").strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Function to convert duration from ISO 8601 to MySQL TIME format\n",
    "    def convert_to_mysql_time(iso_duration):\n",
    "        try:\n",
    "            duration = isodate.parse_duration(iso_duration)\n",
    "            if isinstance(duration, timedelta):\n",
    "                total_seconds = int(duration.total_seconds())\n",
    "                hours = total_seconds // 3600\n",
    "                minutes = (total_seconds % 3600) // 60\n",
    "                seconds = total_seconds % 60\n",
    "                return f'{hours:02}:{minutes:02}:{seconds:02}'\n",
    "        except (isodate.ISO8601Error, TypeError):\n",
    "            return None  # Return None if the format is invalid\n",
    "\n",
    "    # Connect to MySQL\n",
    "    mydb = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        passwd='root',\n",
    "        database='youtube'\n",
    "    )\n",
    "\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    # Drop the table if it exists\n",
    "    drop_query = '''DROP TABLE IF EXISTS videos'''\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    # Create the table\n",
    "    try:\n",
    "        create_query = '''CREATE TABLE IF NOT EXISTS videos (\n",
    "                            Channel_Names VARCHAR(255),\n",
    "                            channel_Id VARCHAR(255),\n",
    "                            Video_Id VARCHAR(255) PRIMARY KEY,\n",
    "                            Title VARCHAR(255),\n",
    "                            Tags TEXT,\n",
    "                            Thumbnail VARCHAR(1000),\n",
    "                            Description TEXT,\n",
    "                            Published_Date DATE,\n",
    "                            Duration TIME,\n",
    "                            Views INT,\n",
    "                            Comments INT,\n",
    "                            Favorite_Count INT,\n",
    "                            Definition VARCHAR(50),\n",
    "                            Caption_Status VARCHAR(50)\n",
    "                        )'''\n",
    "        \n",
    "        cursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error creating table: {err}\")\n",
    "        \n",
    "\n",
    "    # Fetch video information from MongoDB\n",
    "    video_data_list = []  # List to hold all videos for all channels\n",
    "    coll1 = db[\"channel_details\"]\n",
    "\n",
    "    for ch_data in coll1.find({}, {\"_id\": 0, \"video_information\": 1}):\n",
    "        # Check if the channel has video information and accumulate all videos\n",
    "        if \"video_information\" in ch_data:\n",
    "            video_data_list.extend(ch_data[\"video_information\"])\n",
    "\n",
    "    # Convert the fetched data into a DataFrame\n",
    "    if video_data_list:\n",
    "        df_single_channel = pd.DataFrame(video_data_list)\n",
    "    else:\n",
    "        df_single_channel = pd.DataFrame()  # Handle empty data scenario\n",
    "\n",
    "    # Convert datetime values to MySQL-compatible format\n",
    "    if 'Published_Date' in df_single_channel.columns:\n",
    "        df_single_channel['Published_Date'] = df_single_channel['Published_Date'].apply(lambda x: convert_to_mysql_datetime(x) if isinstance(x, str) else x)\n",
    "\n",
    "    # Convert duration values to MySQL-compatible TIME format\n",
    "    if 'Duration' in df_single_channel.columns:\n",
    "        df_single_channel['Duration'] = df_single_channel['Duration'].apply(lambda x: convert_to_mysql_time(x) if isinstance(x, str) else x)\n",
    "\n",
    "    # Check for and handle dictionary types\n",
    "    def handle_dict(value):\n",
    "        if isinstance(value, dict):\n",
    "            # Extract the default URL if it exists\n",
    "            if 'default' in value and 'url' in value['default']:\n",
    "                return value['default']['url']\n",
    "            else:\n",
    "                return json.dumps(value)  # Fallback to JSON string for complex dicts\n",
    "        return value\n",
    "\n",
    "    # Insert DataFrame rows into the MySQL table\n",
    "    insert_query = '''INSERT INTO videos(\n",
    "                        Channel_Names,\n",
    "                        channel_Id,\n",
    "                        Video_Id,\n",
    "                        Title,\n",
    "                        Tags,\n",
    "                        Thumbnail,\n",
    "                        Description,\n",
    "                        Published_Date,\n",
    "                        Duration,\n",
    "                        Views,\n",
    "                        Comments,\n",
    "                        Favorite_Count,\n",
    "                        Definition,\n",
    "                        Caption_Status\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "    for index, row in df_single_channel.iterrows():\n",
    "        values = (\n",
    "            handle_dict(row.get('Channel_Names')),\n",
    "            handle_dict(row.get('channel_Id')),\n",
    "            handle_dict(row.get('Video_Id')),\n",
    "            handle_dict(row.get('Title')),\n",
    "            handle_dict(row.get('Tags')),\n",
    "            handle_dict(row.get('Thumbnail')),\n",
    "            handle_dict(row.get('Description')),\n",
    "            handle_dict(row.get('Published_Date')),\n",
    "            handle_dict(row.get('Duration')),\n",
    "            handle_dict(row.get('Views')),\n",
    "            handle_dict(row.get('Comments')),\n",
    "            handle_dict(row.get('Favorite_Count')),\n",
    "            handle_dict(row.get('Definition')),\n",
    "            handle_dict(row.get('Caption_Status'))\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            cursor.execute(insert_query, values)\n",
    "            mydb.commit()\n",
    "        except mysql.connector.IntegrityError as ie:\n",
    "            print(f\"IntegrityError: Record with Video_Id {row['Video_Id']} already exists. Skipping.\")\n",
    "        except mysql.connector.DataError as de:\n",
    "            print(f\"DataError: {de}\")\n",
    "            print(f\"Problematic data: {values}\")\n",
    "            mydb.rollback()\n",
    "        except mysql.connector.Error as err:\n",
    "            print(f\"Error inserting data: {err}\")\n",
    "            mydb.rollback()\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    mydb.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to MySQL database...\n",
      "Connected to MySQL database.\n",
      "Dropped existing videos table (if it existed).\n",
      "Videos table created successfully.\n",
      "Connecting to MongoDB...\n",
      "Connected to MongoDB.\n",
      "IntegrityError: Record with Video_Id Iwgj6T8OPT8 already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id exjfLOH9IY4 already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id KLBdabZ_i6Y already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id SwCkexMKwA8 already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id cyvDkpLh248 already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id 9mVks4IR-xQ already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id Bur4Rjair4k already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id jsPPJMmfyjI already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id MeXe35xd9_0 already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id sQ5mdm-N_Xo already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id W1H6RsFZ6uk already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id ofWyFqrow3M already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id jPz-gpn_rm4 already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id f_T-lN3zqK8 already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id iNRedRELPBw already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id R-kO5ZZY47w already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id BrX_Vh37a4k already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id pAwkGe_Qe8o already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id y577gMG8u3o already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id pgNE6381MCo already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id Ls45ehnjW6Y already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id HH1d16aeDFE already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id 6oAELHNH2zY already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id sPV9X0x6Oeg already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id axdWCEk65RI already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id qiVwEtYtTjo already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id SqsP5wCqLXc already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id ULVFetwMeBI already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id U2A4nYw_rR0 already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id 8pK_njBtNdg already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id ltRTXrbpXYM already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id ont6nyjgYVQ already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id A88dvfcICrU already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id 84lPUHg0sFo already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id iIsZzOeTn-8 already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id oftn64D9LsA already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id LSPBYoqqcPE already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id TU-t9_C7QjU already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id _qzWsQG2izU already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id lET0dZDZnqc already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id dD6mEgyEGAk already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id vHiQoPJhfrs already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id 9hnuA4imiAE already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id gBwEJ-2DPQc already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id BdoCNd_5qEs already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id fxp5Nism024 already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id MW5dLYsi-l4 already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id fR9QylOAwnY already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id OTLavrhbNCg already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id 9_S1VajqoDM already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id HMAY9gkvwFo already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id _rQzHuApgXs already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id bosRfQ0ew00 already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id vwpxrKowgc8 already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id aENAaJ2ysuQ already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id YBgc3oruiQU already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id Gv17f9XkJWI already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id JaxG2A4T8GI already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id U5kd9HmM94U already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id KYA9w0BWQcs already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id vAEsq9NGxAI already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id IAZcAwG_Mhg already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id j3RNC1iYOqU already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id qdpN6J2n3pY already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id lwkffcQ2Zt0 already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id 9nEINER6kJM already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id PnRHcL_-iHA already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id ETkFs-hYEQc already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id -FVq8EVJTvk already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id 0iKRy2zGW8o already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id 6XFUXIJf-As already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id Jdbd9wwYAp4 already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id eNfU9Z5yGyM already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id 0T43gMWV8qM already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id PfFmOIsXWCU already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id UvAxsaNE2BI already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id HX-hMkKf5DA already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id nBEoB0nEIhw already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id SI0NA6k-lME already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id h4B3Psww4vo already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id uKnHTsFXWTU already exists. Skipping.\n",
      "IntegrityError: Record with Video_Id OYW2HKrmfek already exists. Skipping.\n",
      "MySQL connection closed.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timedelta\n",
    "import isodate\n",
    "import json\n",
    "\n",
    "def videos_table(channel_name):\n",
    "\n",
    "    # Function to convert datetime from ISO 8601 to MySQL format\n",
    "    def convert_to_mysql_datetime(iso_datetime):\n",
    "        return datetime.strptime(iso_datetime, \"%Y-%m-%dT%H:%M:%SZ\").strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Function to convert duration from ISO 8601 to MySQL TIME format\n",
    "    def convert_to_mysql_time(iso_duration):\n",
    "        try:\n",
    "            duration = isodate.parse_duration(iso_duration)\n",
    "            if isinstance(duration, timedelta):\n",
    "                total_seconds = int(duration.total_seconds())\n",
    "                hours = total_seconds // 3600\n",
    "                minutes = (total_seconds % 3600) // 60\n",
    "                seconds = total_seconds % 60\n",
    "                return f'{hours:02}:{minutes:02}:{seconds:02}'\n",
    "        except (isodate.ISO8601Error, TypeError):\n",
    "            return None  # Return None if the format is invalid\n",
    "\n",
    "    # Connect to MySQL\n",
    "    print(\"Connecting to MySQL database...\")\n",
    "    mydb = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        passwd='root',\n",
    "        database='youtube'\n",
    "    )\n",
    "    cursor = mydb.cursor()\n",
    "    print(\"Connected to MySQL database.\")\n",
    "\n",
    "    # Drop the table if it exists\n",
    "    try:\n",
    "        drop_query = '''DROP TABLE IF EXISTS videos'''\n",
    "        cursor.execute(drop_query)\n",
    "        mydb.commit()\n",
    "        print(\"Dropped existing videos table (if it existed).\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error dropping table: {e}\")\n",
    "\n",
    "    # Create the table\n",
    "    try:\n",
    "        create_query = '''CREATE TABLE IF NOT EXISTS videos (\n",
    "                            Channel_Names VARCHAR(255),\n",
    "                            channel_Id VARCHAR(255),\n",
    "                            Video_Id VARCHAR(255) PRIMARY KEY,\n",
    "                            Title VARCHAR(255),\n",
    "                            Tags TEXT,\n",
    "                            Thumbnail VARCHAR(1000),\n",
    "                            Description TEXT,\n",
    "                            Published_Date DATETIME,\n",
    "                            Duration TIME,\n",
    "                            Views INT,\n",
    "                            Comments INT,\n",
    "                            Favorite_Count INT,\n",
    "                            Definition VARCHAR(50),\n",
    "                            Caption_Status VARCHAR(50)\n",
    "                        )'''\n",
    "        \n",
    "        cursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "        print(\"Videos table created successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error creating table: {err}\")\n",
    "\n",
    "    # Connect to MongoDB\n",
    "    print(\"Connecting to MongoDB...\")\n",
    "   \n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    print(\"Connected to MongoDB.\")\n",
    "\n",
    "    # Fetch video information from MongoDB\n",
    "    video_data_list = []  # List to hold all videos\n",
    "    for ch_data in coll1.find({}, {\"_id\": 0, \"video_information\": 1}):\n",
    "        if \"video_information\" in ch_data:\n",
    "            video_data_list.extend(ch_data[\"video_information\"])\n",
    "\n",
    "    # Convert the fetched data into a DataFrame\n",
    "    df_single_channel = pd.DataFrame(video_data_list)\n",
    "\n",
    "    # Convert datetime values to MySQL-compatible format\n",
    "    if 'Published_Date' in df_single_channel.columns:\n",
    "        df_single_channel['Published_Date'] = df_single_channel['Published_Date'].apply(\n",
    "            lambda x: convert_to_mysql_datetime(x) if isinstance(x, str) else x\n",
    "        )\n",
    "\n",
    "    # Convert duration values to MySQL-compatible TIME format\n",
    "    if 'Duration' in df_single_channel.columns:\n",
    "        df_single_channel['Duration'] = df_single_channel['Duration'].apply(\n",
    "            lambda x: convert_to_mysql_time(x) if isinstance(x, str) else x\n",
    "        )\n",
    "\n",
    "    # Handle dictionary types\n",
    "    def handle_dict(value):\n",
    "        if isinstance(value, dict):\n",
    "            if 'default' in value and 'url' in value['default']:\n",
    "                return value['default']['url']\n",
    "            else:\n",
    "                return json.dumps(value)\n",
    "        return value\n",
    "\n",
    "    # Insert DataFrame rows into the MySQL table\n",
    "    insert_query = '''INSERT INTO videos(\n",
    "                        Channel_Names,\n",
    "                        channel_Id,\n",
    "                        Video_Id,\n",
    "                        Title,\n",
    "                        Tags,\n",
    "                        Thumbnail,\n",
    "                        Description,\n",
    "                        Published_Date,\n",
    "                        Duration,\n",
    "                        Views,\n",
    "                        Comments,\n",
    "                        Favorite_Count,\n",
    "                        Definition,\n",
    "                        Caption_Status\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "    for index, row in df_single_channel.iterrows():\n",
    "        values = (\n",
    "            handle_dict(row.get('Channel_Names')),\n",
    "            handle_dict(row.get('channel_Id')),\n",
    "            handle_dict(row.get('Video_Id')),\n",
    "            handle_dict(row.get('Title')),\n",
    "            handle_dict(row.get('Tags')),\n",
    "            handle_dict(row.get('Thumbnail')),\n",
    "            handle_dict(row.get('Description')),\n",
    "            handle_dict(row.get('Published_Date')),\n",
    "            handle_dict(row.get('Duration')),\n",
    "            handle_dict(row.get('Views')),\n",
    "            handle_dict(row.get('Comments')),\n",
    "            handle_dict(row.get('Favorite_Count')),\n",
    "            handle_dict(row.get('Definition')),\n",
    "            handle_dict(row.get('Caption_Status'))\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            cursor.execute(insert_query, values)\n",
    "            mydb.commit()\n",
    "        except mysql.connector.IntegrityError as ie:\n",
    "            print(f\"IntegrityError: Record with Video_Id {row['Video_Id']} already exists. Skipping.\")\n",
    "        except mysql.connector.DataError as de:\n",
    "            print(f\"DataError: {de}\")\n",
    "            print(f\"Problematic data: {values}\")\n",
    "            mydb.rollback()\n",
    "        except mysql.connector.Error as err:\n",
    "            print(f\"Error inserting data: {err}\")\n",
    "            mydb.rollback()\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    mydb.close()\n",
    "    print(\"MySQL connection closed.\")\n",
    "\n",
    "# Make sure to call the function\n",
    "videos_table(\"some_channel_name\")  # Replace with an actual channel name if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to MySQL database...\n",
      "Connected to MySQL database.\n",
      "Dropped existing playlists table (if it existed).\n",
      "Playlists table created successfully.\n",
      "Connecting to MongoDB...\n",
      "Connected to MongoDB.\n",
      "Fetching playlist information from MongoDB...\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QtBfZjxfrgGy3481rQYyzR\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QV8RhlLQLpG6vR3BnkgvQR\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RsyqQ-ZDSTVN-8VA5_DZzD\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2R35TpL1IV0vm74xlCc5BEV\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2R8fdY2Q_qLqeuAtsXZPPtL\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QBE0B1t-jKt1V6a8yfF8QC\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Ts1Dgxn_vdG4f9FrjEOeAV\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TJjpp8riTumjegf5DbvlJQ\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SgRVxEE3SiXP3PK3kFvG06\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2ToTjZcBnbmMkV3DX2RCUWk\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QkO2L1euBIEzGUTIbSxYRk\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TmkWPtnB6UAzBKD-_QTtoK\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RMWydMAIa17bU4I19z1j9m\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RS6qq9sZmmflS36Qe0PZ86\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2S2FubdW9YVWU4KfRyO3KRk\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QQBd4CawYd01Pi1jR8Uu6J\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Sdmd9grNt-gYCxEx49Mgix\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RAwTbepaqWF5p7SYSqRulc\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SUGa1ZeISC0XpzY3S_F9e3\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Qn7TZ3crWR4tgY1Bn9rQW_\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TU6Oh5bQ9jFwhuRoqpv4qf\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2S3NhmOHZyP_RMfPHVWOhAE\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Tau2B--9cJB6P5394XN42O\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RgepAAy7k-W3IAQfDYc5zn\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QFd-TJbk1h6mOG9JZKSBCF\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RnkW0Xynq7GRE6Px4HDrdO\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RVKadmpl-GUACkB8xkWlTJ\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TVY2_N3isP87-5eeePWIbi\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TDfPL9CdztEosHlE4iBJRN\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RPIpeCjE1kfd8uiQC1miRZ\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2T9IyzWm_dlYSu_KDIu80iz\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RErCkkztTn8-hyS8dFRiaR\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SZcnb3tolk7QzdCS2ztD85\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SESzpXwXcIgV_n84gaQSyF\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TztRKzKiBJEM6W-skCOe_v\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SGRYu-x_fwviLVorvXkbNr\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RuB5cY_LZbYt8whv0Rljkf\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Tpl7l_D75ukZ80kSzdteDL\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2R6uuHY0XAkutIxFXInS_mL\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2T6RlbV4noYt74URKkpuJFi\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Rj0TAxrbVLqbTT9zRzUJbk\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2ROxSoYI0SzjEc7ND2rhnec\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SOAu3lsp-SIiIoUIqZ-n93\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Q2lNhJomQSLbWNj0pl6Sj0\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RPrwWWehJebeWa5rNqiqOz\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TNuGeMHYZ12AS-nWONtkkY\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TiNlS4NUIXfdFV-kPxMGvc\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SmLdCZh1kQrlC6HG7QuEqw\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TFHVKds3u52RMP43cOjIea\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QCiiJYLSShfTtXXTTwx44n\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RzGSw6rrFKmj47oJaiaFJv\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TVwfUFSgviqf1r5EKQYsxP\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QcBjhXAGbJV8Nrcv4ECrpG\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2THYOGMuFqeIVaoJ47axC-m\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TuLPdYX_DKQFCBwy52wjJj\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QuuiN9OX2wQkwFzofwdn_N\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QHo-_aF0dH3UDPm0J5wYik\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SKVJ8BGX-LX5N16M5l986L\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SJeD4oxJZcmrUWUPI2vHb0\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QMaY9FOFD9j1EshdIXVcvD\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SmWTBgsdTCTyMrI2ahFxI2\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TXAd1jPZYQh1pE8KfpKhuK\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TmXv4XIdaCOue0ZUBt6G5t\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RKgfX1mOT7oaDFgkvZZ7C2\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Sb-VLtINFTSk7_HSaAT-b2\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2THZA4IwSc2ihZMjWXb1tpr\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TwhwvpvkO1vju9JRss7hhr\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SsL1THAGUTmCSqWampvv6e\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2T9PbOSbebD3v9MzqYDuQh2\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SGY0blbgKVN74nTwIB9ckI\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TmNagx7zGwWgcG01c9eQJh\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2S40TKjP8RAtzm1piAQsh-6\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2T9tVh0GvrG7kMo5CKY_e99\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SXVU6W_c0RBZx9zqpvl1UR\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RtdQ88kw2ajo1W68H1JCS7\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Q4DpF2wsedTzk2ss6TpBUd\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TSSCZ5vl1kGNHKxG0B-itm\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Qn8VsYrrZxXaA7dLGzNfoI\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RLAdr86tqOOcA76nr_tjLc\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SBaw8FGDQX81IGLHNcCvJd\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QjXUnH9ZBSVsMnTf71FVVj\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Q6CXgcXqw7nUa6W-m5DBV7\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Snn2380GQGiq_pIs1vMFkA\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TK1I8XqdGlcT4rckvjJTDt\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Q3rpcDWrPybqWL2dGJu8dm\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RjU8uMmJJCWcTTyBWNoyuL\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SB76p0uNfqEHkg9ggp0KkV\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RldIhz_EJF2D_W5QB2IVgl\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RaY-t7l4zp9vOAkCPV9s5l\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2S9PGd-jA_V_lQWZKZNKhH5\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RrLZg3yZ5EXG1LUXAr9l2s\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Qpa8HFW53dMfPDQ1a_u7Ku\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RokTZFE5uizJw7MCQeJq6x\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Tq3tA06w1y6RaBQDH7r8R0\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2StbfU9WTfKGruPPScYEDeo\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RRKkR2608p4cYa4321euG5\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QcV0URiD2h1XXVkojNg-jX\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Tj-vHYFDs9BxSRO1rRdnh0\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QFzdJraefbm2yIyRWs0Rg7\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SnF6cM8mBjmQq_3C74xh_j\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2T0EjuzDxoOabEbKujbuVDv\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RaQlI0mNCOdqckcDuJlepp\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TnuZtqWzVkCHREjSjiYwnN\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RNQfWEzWuH64whWPloIsFH\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2T9vxZOg80APH9f8SxIuV9W\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TG81LpwXjxyO1tU-7aPIHZ\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RFDjPKhz94Sls_kjeKDMvY\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Qmrff5x8t3MxFzzvAo5kms\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QgUN07VlVpQwpTLxMujzNZ\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RRaG4kxeEEg8Tb69jNHDzZ\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2S1bKQCh8dEvR1cMfMsug6_\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SiSh_skeDOWX7zyCFRQ1kq\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QJVtXJ4mcBVtt6fVEPxK7y\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TP3xCCBFg-WJoSGhymJwOH\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2THvnhntQBRs00943dUTrBZ\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2R6AzaF6CYRvBJ1AmCxx6NJ\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RF7fp1otjmXfKV0e-8MU3g\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RKFBT2fCWxbISop0Q_aGdP\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2R1ufOfn-KV6NiOwaJ4OY8w\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Re2NP8EUZvAFcGz3q5w_rv\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2S3exDRqZHhTcJzKmzniN_H\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SvI0vpBZqCi7qcWWnH4r1Z\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QPhvLVBLve--1_EDdNbT_d\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QnPohfQqCFag2J3SwmWkiN\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QMZjqnSyvXlvc08ePnhcK8\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2R6rAy05a2IJoeyDECJ4WpH\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RBDld8JO_U6mfxQ2YuDJ_U\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RrgFZHwLcEpujjd2O5_UIr\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QFaAo1Vx4W_nUiWlPegaMN\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2R0DTXV2r4ZOtHoaYtah7V8\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Tp9R53lDMf40tlC0ij2EFW\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TVfC5O4abwDHRgLpPyUEmu\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Syda__D-kAz1nAkwReXuFa\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Rr738OY6TxnmVLVI5V_wlG\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QROpMaL_eE77uvSP55wOef\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2ROs_bue4X__W4KFhqm0tp9\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TQ2j_k8EJ0inDjji-8cns2\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QoD4yHHzbiCxwrhPEUedFB\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RUmIwHBa-rHQyW2ca2ysOp\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Q3Bn0q2lopY-1Sw6Nwl35k\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RuoGxovvb7bg3uOIPI5DpM\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2S7VZqBGQu730Yw36kSOzBf\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2T970sVmcyb5oUFStjy1EAH\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SM5WInZGuZJG-KHp-LB-OW\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SrJTQ3r6p5ntIePlz9GOgK\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QXTp-zIa2AnOs1bu0v7WVt\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TfDaejA9NGGRQuqpR3vmvs\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2T4DWPzxdhsXXMQ7mHwWVA8\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RmG1Kl1bckqKmDCz-qEgp3\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TiwTf7bzs9imkTb6OMpO3d\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RfbdKX19mCdghR6G6WcKB8\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QnBli91fyfaO_Gq29dF0hk\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Spk4Kn1GpqDxpwgXV2h8EA\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SMwaUPcJb7S6ggXlkNlDpD\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RuRQqtpB-Twuj6X3dIVor5\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RGA6x8u_9nT0E3oV5o8bLh\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2RBs0M5SMmHHQN6R6mPkqJO\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2S9d6wtRWraEugNEfYZHF6u\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TTotBQujbxkqzM_nuAj8-C\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QHoir2hjCxx_BQnWgpNFF0\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QzDkqwbTesWWkhhDKGa-9W\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QYSGrq2ajo7NxbPb73Smfg\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2R5s9CpdYW0cHUXS2U5n0UA\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QONJt7mGPgET6jlXnlRhgH\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2T0UOGclKwvT1lO3uuJtvp8\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2Q7784QYcSUTVIK8IUzTcqa\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QhjDPS7rSg88JG4kNvdncG\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QBaSZVreB_ZEQNjHP9pWCb\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2SYtboX_ECP50rexgUu4i03\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QD9Q49aObB7tI55FF45dxc\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2QO1umUcFAv2kWgiluA3vsn\n",
      "Inserted Playlist_Id: PLSwH4ViBDl2TlEOT0-KXz0MZn8_RkdIGg\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_dIPbFgNzHMLTcuiBMOlyzw\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_dVZxkYrgtbnvHBza3JqX97\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_ePsfolNltpSY3MmoRkRhsL\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_d4Fvgbd3dZhWGArTiUws-m\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_ckocrGeOnN-0llw66SGND8\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_cUJTI_9Ny_n4815ndG4Yx2\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_fczif1y4xlYgZoVE9hlj2S\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_cVOovw_eT7DqbsLMgtDq_R\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_cgH0knEMuRseLpu2yAqU95\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_cyjQMM7ileiiAcC3aSBe65\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_ctvRTTfYUundZM-x2bPsA5\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_cg0-6M_DKwFSvM8OqpV8BX\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_egRQ_xrd_xVBImmyS1LVXM\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_dcLBHI4a-Ec3aUV3RL7kex\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_ejhHX7P9bp6lHYoR8i8Zgc\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_eJpddyoh-OGDWvEO3ob5kQ\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_d2YVNFuj9yThnwcwtrTB4t\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_d7dWVwF_ur61deMxU0bRka\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_fzIMbHBeG65oXwyFA-xRwh\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_dnRr_rwXOubqXutowOKq-D\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_dSQ6NWkzofJVp7kQXKDlWZ\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_d98A7rMS1K39r-jkaXdGTi\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_coZ-yy69MP39oRMoX-yYhU\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_dWxUgIv1PEtbBdRR7AWa-v\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_eV725o-_86vPakAMBTKld3\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_eDDRsL9MXgJRaksJPGekJx\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_e_Uy8meR0OjvJQqAfmMXc9\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_fZ4TC483fTUkd1bLU_dB7I\n",
      "Inserted Playlist_Id: PLX9ciqY-LU_f8jZdr_8YRj9RTqs-vKhcv\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_dIPbFgNzHMLTcuiBMOlyzw already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_dVZxkYrgtbnvHBza3JqX97 already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_ePsfolNltpSY3MmoRkRhsL already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_d4Fvgbd3dZhWGArTiUws-m already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_ckocrGeOnN-0llw66SGND8 already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_cUJTI_9Ny_n4815ndG4Yx2 already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_fczif1y4xlYgZoVE9hlj2S already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_cVOovw_eT7DqbsLMgtDq_R already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_cgH0knEMuRseLpu2yAqU95 already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_cyjQMM7ileiiAcC3aSBe65 already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_ctvRTTfYUundZM-x2bPsA5 already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_cg0-6M_DKwFSvM8OqpV8BX already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_egRQ_xrd_xVBImmyS1LVXM already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_dcLBHI4a-Ec3aUV3RL7kex already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_ejhHX7P9bp6lHYoR8i8Zgc already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_eJpddyoh-OGDWvEO3ob5kQ already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_d2YVNFuj9yThnwcwtrTB4t already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_d7dWVwF_ur61deMxU0bRka already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_fzIMbHBeG65oXwyFA-xRwh already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_dnRr_rwXOubqXutowOKq-D already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_dSQ6NWkzofJVp7kQXKDlWZ already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_d98A7rMS1K39r-jkaXdGTi already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_coZ-yy69MP39oRMoX-yYhU already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_dWxUgIv1PEtbBdRR7AWa-v already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_eV725o-_86vPakAMBTKld3 already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_eDDRsL9MXgJRaksJPGekJx already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_e_Uy8meR0OjvJQqAfmMXc9 already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_fZ4TC483fTUkd1bLU_dB7I already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_f8jZdr_8YRj9RTqs-vKhcv already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_dIPbFgNzHMLTcuiBMOlyzw already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_dVZxkYrgtbnvHBza3JqX97 already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_ePsfolNltpSY3MmoRkRhsL already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_d4Fvgbd3dZhWGArTiUws-m already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_ckocrGeOnN-0llw66SGND8 already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_cUJTI_9Ny_n4815ndG4Yx2 already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_fczif1y4xlYgZoVE9hlj2S already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_cVOovw_eT7DqbsLMgtDq_R already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_cgH0knEMuRseLpu2yAqU95 already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_cyjQMM7ileiiAcC3aSBe65 already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_ctvRTTfYUundZM-x2bPsA5 already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_cg0-6M_DKwFSvM8OqpV8BX already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_egRQ_xrd_xVBImmyS1LVXM already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_dcLBHI4a-Ec3aUV3RL7kex already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_ejhHX7P9bp6lHYoR8i8Zgc already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_eJpddyoh-OGDWvEO3ob5kQ already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_d2YVNFuj9yThnwcwtrTB4t already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_d7dWVwF_ur61deMxU0bRka already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_fzIMbHBeG65oXwyFA-xRwh already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_dnRr_rwXOubqXutowOKq-D already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_dSQ6NWkzofJVp7kQXKDlWZ already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_d98A7rMS1K39r-jkaXdGTi already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_coZ-yy69MP39oRMoX-yYhU already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_dWxUgIv1PEtbBdRR7AWa-v already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_eV725o-_86vPakAMBTKld3 already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_eDDRsL9MXgJRaksJPGekJx already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_e_Uy8meR0OjvJQqAfmMXc9 already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_fZ4TC483fTUkd1bLU_dB7I already exists. Skipping.\n",
      "IntegrityError: Record with Playlist_Id PLX9ciqY-LU_f8jZdr_8YRj9RTqs-vKhcv already exists. Skipping.\n",
      "MySQL connection closed.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "\n",
    "def playlist_table(channel_name):\n",
    "\n",
    "    # Function to convert datetime from ISO 8601 to MySQL format\n",
    "    def convert_to_mysql_datetime(iso_datetime):\n",
    "        try:\n",
    "            return datetime.strptime(iso_datetime, \"%Y-%m-%dT%H:%M:%SZ\").strftime('%Y-%m-%d %H:%M:%S')\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting datetime: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Connect to MySQL\n",
    "    print(\"Connecting to MySQL database...\")\n",
    "    mydb = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        passwd='root',\n",
    "        database='youtube'\n",
    "    )\n",
    "    cursor = mydb.cursor()\n",
    "    print(\"Connected to MySQL database.\")\n",
    "\n",
    "    # Drop the table if it exists\n",
    "    try:\n",
    "        drop_query = '''DROP TABLE IF EXISTS playlists'''\n",
    "        cursor.execute(drop_query)\n",
    "        mydb.commit()\n",
    "        print(\"Dropped existing playlists table (if it existed).\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error dropping table: {e}\")\n",
    "\n",
    "    # Create the table\n",
    "    try:\n",
    "        create_query = '''CREATE TABLE IF NOT EXISTS playlists(\n",
    "                            Playlist_Id VARCHAR(100) PRIMARY KEY,\n",
    "                            Title VARCHAR(100),\n",
    "                            Channel_Id VARCHAR(100),\n",
    "                            Channel_Name VARCHAR(100),\n",
    "                            PublishedAt TIMESTAMP,\n",
    "                            Video_Count INT\n",
    "                        )'''\n",
    "        cursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "        print(\"Playlists table created successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error creating table: {err}\")\n",
    "\n",
    "    # Connect to MongoDB\n",
    "    print(\"Connecting to MongoDB...\")\n",
    "    \n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    print(\"Connected to MongoDB.\")\n",
    "\n",
    "    # Fetch playlist information from MongoDB\n",
    "    print(\"Fetching playlist information from MongoDB...\")\n",
    "    single_channel_details = []\n",
    "    for ch_data in coll1.find({}, {\"_id\": 0, \"playlist_information\": 1}):\n",
    "        if \"playlist_information\" in ch_data:\n",
    "            single_channel_details.extend(ch_data[\"playlist_information\"])\n",
    "\n",
    "    # Convert the fetched data into a DataFrame\n",
    "    df_single_channel = pd.DataFrame(single_channel_details)\n",
    "\n",
    "    # Convert the datetime strings to MySQL-compatible format\n",
    "    if 'PublishedAt' in df_single_channel.columns:\n",
    "        df_single_channel['PublishedAt'] = df_single_channel['PublishedAt'].apply(convert_to_mysql_datetime)\n",
    "\n",
    "    # Insert DataFrame rows into the MySQL table\n",
    "    insert_query = '''INSERT INTO playlists(\n",
    "                        Playlist_Id,\n",
    "                        Title,\n",
    "                        Channel_Id,\n",
    "                        Channel_Name,\n",
    "                        PublishedAt,\n",
    "                        Video_Count\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "    for index, row in df_single_channel.iterrows():\n",
    "        values = (\n",
    "            row['Playlist_Id'],\n",
    "            row['Title'],\n",
    "            row['Channel_Id'],\n",
    "            row['Channel_Name'],\n",
    "            row['PublishedAt'],\n",
    "            row['Video_Count']\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            cursor.execute(insert_query, values)\n",
    "            mydb.commit()\n",
    "            print(f\"Inserted Playlist_Id: {row['Playlist_Id']}\")\n",
    "        except mysql.connector.IntegrityError as ie:\n",
    "            print(f\"IntegrityError: Record with Playlist_Id {row['Playlist_Id']} already exists. Skipping.\")\n",
    "        except mysql.connector.DataError as de:\n",
    "            print(f\"DataError: {de}\")\n",
    "            print(f\"Problematic data: {values}\")\n",
    "            mydb.rollback()\n",
    "        except mysql.connector.Error as err:\n",
    "            print(f\"Error inserting data: {err}\")\n",
    "            mydb.rollback()\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    mydb.close()\n",
    "    print(\"MySQL connection closed.\")\n",
    "\n",
    "# Make sure to call the function\n",
    "playlist_table(\"some_channel_name\")  # Replace with an actual channel name if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tables(channel_name):\n",
    "\n",
    "    news= channels_table(channel_name)\n",
    "    if news:\n",
    "        st.write(news) \n",
    "    else:\n",
    "        playlist_table(channel_name)\n",
    "        videos_table(channel_name)\n",
    "        comments_table(channel_name)\n",
    "\n",
    "    return \"Tables Created Successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to MySQL database...\n",
      "Connected to MySQL database.\n",
      "Dropped existing playlists table (if it existed).\n",
      "Playlists table created successfully.\n",
      "Connecting to MongoDB...\n",
      "Connected to MongoDB.\n",
      "Fetching playlist information from MongoDB...\n"
     ]
    },
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "localhost:27017: [WinError 10061] No connection could be made because the target machine actively refused it (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6703fa410f3434e93b23e78d, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] No connection could be made because the target machine actively refused it (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 113\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMySQL connection closed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Make sure to call the function\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m \u001b[43mplaylist_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msome_channel_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Replace with an actual channel name if needed\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 62\u001b[0m, in \u001b[0;36mplaylist_table\u001b[1;34m(channel_name)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching playlist information from MongoDB...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m single_channel_details \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 62\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mch_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcoll1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplaylist_information\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplaylist_information\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mch_data\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43msingle_channel_details\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplaylist_information\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\pymongo\\cursor.py:1243\u001b[0m, in \u001b[0;36mCursor.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__empty:\n\u001b[0;32m   1242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m-> 1243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__data) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_refresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__data\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\pymongo\\cursor.py:1160\u001b[0m, in \u001b[0;36mCursor._refresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidOperation(\n\u001b[0;32m   1139\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhint\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is required when using the min/max query\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1140\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m option to ensure the query utilizes the correct index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1141\u001b[0m         )\n\u001b[0;32m   1142\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_class(\n\u001b[0;32m   1143\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__query_flags,\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__collection\u001b[38;5;241m.\u001b[39mdatabase\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__exhaust,\n\u001b[0;32m   1159\u001b[0m     )\n\u001b[1;32m-> 1160\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__id:  \u001b[38;5;66;03m# Get More\u001b[39;00m\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__limit:\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\pymongo\\cursor.py:1039\u001b[0m, in \u001b[0;36mCursor.__send_message\u001b[1;34m(self, operation)\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidOperation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexhaust cursors do not support auto encryption\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1039\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unpack_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__address\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailure \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01min\u001b[39;00m _CURSOR_CLOSED_ERRORS \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__exhaust:\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;66;03m# Don't send killCursors because the cursor is already closed.\u001b[39;00m\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\pymongo\\_csot.py:108\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[0;32m    107\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\pymongo\\mongo_client.py:1431\u001b[0m, in \u001b[0;36mMongoClient._run_operation\u001b[1;34m(self, operation, unpack_res, address)\u001b[0m\n\u001b[0;32m   1421\u001b[0m     operation\u001b[38;5;241m.\u001b[39mreset()  \u001b[38;5;66;03m# Reset op in case of retry.\u001b[39;00m\n\u001b[0;32m   1422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m server\u001b[38;5;241m.\u001b[39mrun_operation(\n\u001b[0;32m   1423\u001b[0m         conn,\n\u001b[0;32m   1424\u001b[0m         operation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1429\u001b[0m     )\n\u001b[1;32m-> 1431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retryable_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1432\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_cmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1433\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_preference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1434\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1435\u001b[0m \u001b[43m    \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretryable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Query\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\pymongo\\mongo_client.py:1540\u001b[0m, in \u001b[0;36mMongoClient._retryable_read\u001b[1;34m(self, func, read_pref, session, operation, address, retryable, operation_id)\u001b[0m\n\u001b[0;32m   1535\u001b[0m \u001b[38;5;66;03m# Ensure that the client supports retrying on reads and there is no session in\u001b[39;00m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# transaction, otherwise, we will not support retry behavior for this call.\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m retryable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\n\u001b[0;32m   1538\u001b[0m     retryable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mretry_reads \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (session \u001b[38;5;129;01mand\u001b[39;00m session\u001b[38;5;241m.\u001b[39min_transaction)\n\u001b[0;32m   1539\u001b[0m )\n\u001b[1;32m-> 1540\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_read\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[43m    \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_pref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_pref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretryable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretryable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1549\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1550\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\pymongo\\_csot.py:108\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[0;32m    107\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\pymongo\\mongo_client.py:1507\u001b[0m, in \u001b[0;36mMongoClient._retry_internal\u001b[1;34m(self, func, session, bulk, operation, is_read, address, read_pref, retryable, operation_id)\u001b[0m\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;129m@_csot\u001b[39m\u001b[38;5;241m.\u001b[39mapply\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_retry_internal\u001b[39m(\n\u001b[0;32m   1472\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1481\u001b[0m     operation_id: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1482\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m   1483\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Internal retryable helper for all client transactions.\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m \n\u001b[0;32m   1485\u001b[0m \u001b[38;5;124;03m    :param func: Callback function we want to retry\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;124;03m    :return: Output of the calling func()\u001b[39;00m\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ClientConnectionRetryable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmongo_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbulk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbulk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1500\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_read\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_read\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_pref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_pref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretryable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretryable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 1507\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\pymongo\\mongo_client.py:2353\u001b[0m, in \u001b[0;36m_ClientConnectionRetryable.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_last_error(check_csot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_read \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write()\n\u001b[0;32m   2354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ServerSelectionTimeoutError:\n\u001b[0;32m   2355\u001b[0m     \u001b[38;5;66;03m# The application may think the write was never attempted\u001b[39;00m\n\u001b[0;32m   2356\u001b[0m     \u001b[38;5;66;03m# if we raise ServerSelectionTimeoutError on the retry\u001b[39;00m\n\u001b[0;32m   2357\u001b[0m     \u001b[38;5;66;03m# attempt. Raise the original exception instead.\u001b[39;00m\n\u001b[0;32m   2358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_last_error()\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\pymongo\\mongo_client.py:2483\u001b[0m, in \u001b[0;36m_ClientConnectionRetryable._read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m   2479\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper method for read-type retryable client executions\u001b[39;00m\n\u001b[0;32m   2480\u001b[0m \n\u001b[0;32m   2481\u001b[0m \u001b[38;5;124;03m    :return: Output for func()'s call\u001b[39;00m\n\u001b[0;32m   2482\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2484\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_pref \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead Preference required on read calls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2485\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_conn_from_server(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_pref, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[0;32m   2486\u001b[0m         conn,\n\u001b[0;32m   2487\u001b[0m         read_pref,\n\u001b[0;32m   2488\u001b[0m     ):\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\pymongo\\mongo_client.py:2439\u001b[0m, in \u001b[0;36m_ClientConnectionRetryable._get_server\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_server\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Server:\n\u001b[0;32m   2435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves a server object based on provided object context\u001b[39;00m\n\u001b[0;32m   2436\u001b[0m \n\u001b[0;32m   2437\u001b[0m \u001b[38;5;124;03m    :return: Abstraction to connect to server\u001b[39;00m\n\u001b[0;32m   2438\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select_server\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2440\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server_selector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2441\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2442\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_operation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2443\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeprioritized_servers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deprioritized_servers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2445\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_operation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\pymongo\\mongo_client.py:1322\u001b[0m, in \u001b[0;36mMongoClient._select_server\u001b[1;34m(self, server_selector, session, operation, address, deprioritized_servers, operation_id)\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m AutoReconnect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserver \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m no longer available\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m address)  \u001b[38;5;66;03m# noqa: UP031\u001b[39;00m\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1322\u001b[0m         server \u001b[38;5;241m=\u001b[39m \u001b[43mtopology\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_server\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m            \u001b[49m\u001b[43mserver_selector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m            \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdeprioritized_servers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeprioritized_servers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m            \u001b[49m\u001b[43moperation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m server\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PyMongoError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;66;03m# Server selection errors in a transaction are transient.\u001b[39;00m\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\pymongo\\topology.py:368\u001b[0m, in \u001b[0;36mTopology.select_server\u001b[1;34m(self, selector, operation, server_selection_timeout, address, deprioritized_servers, operation_id)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_server\u001b[39m(\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    360\u001b[0m     selector: Callable[[Selection], Selection],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m     operation_id: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    366\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Server:\n\u001b[0;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Like select_servers, but choose a random server if several match.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     server \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select_server\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_selection_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeprioritized_servers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _csot\u001b[38;5;241m.\u001b[39mget_timeout():\n\u001b[0;32m    377\u001b[0m         _csot\u001b[38;5;241m.\u001b[39mset_rtt(server\u001b[38;5;241m.\u001b[39mdescription\u001b[38;5;241m.\u001b[39mmin_round_trip_time)\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\pymongo\\topology.py:346\u001b[0m, in \u001b[0;36mTopology._select_server\u001b[1;34m(self, selector, operation, server_selection_timeout, address, deprioritized_servers, operation_id)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_select_server\u001b[39m(\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    339\u001b[0m     selector: Callable[[Selection], Selection],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    344\u001b[0m     operation_id: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    345\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Server:\n\u001b[1;32m--> 346\u001b[0m     servers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_servers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_selection_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_id\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m     servers \u001b[38;5;241m=\u001b[39m _filter_servers(servers, deprioritized_servers)\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(servers) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\pymongo\\topology.py:253\u001b[0m, in \u001b[0;36mTopology.select_servers\u001b[1;34m(self, selector, operation, server_selection_timeout, address, operation_id)\u001b[0m\n\u001b[0;32m    250\u001b[0m     server_timeout \u001b[38;5;241m=\u001b[39m server_selection_timeout\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 253\u001b[0m     server_descriptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select_servers_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maddress\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    258\u001b[0m         cast(Server, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_server_by_address(sd\u001b[38;5;241m.\u001b[39maddress)) \u001b[38;5;28;01mfor\u001b[39;00m sd \u001b[38;5;129;01min\u001b[39;00m server_descriptions\n\u001b[0;32m    259\u001b[0m     ]\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\pymongo\\topology.py:303\u001b[0m, in \u001b[0;36mTopology._select_servers_loop\u001b[1;34m(self, selector, timeout, operation, operation_id, address)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _SERVER_SELECTION_LOGGER\u001b[38;5;241m.\u001b[39misEnabledFor(logging\u001b[38;5;241m.\u001b[39mDEBUG):\n\u001b[0;32m    293\u001b[0m         _debug_log(\n\u001b[0;32m    294\u001b[0m             _SERVER_SELECTION_LOGGER,\n\u001b[0;32m    295\u001b[0m             message\u001b[38;5;241m=\u001b[39m_ServerSelectionStatusMessage\u001b[38;5;241m.\u001b[39mFAILED,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    301\u001b[0m             failure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_message(selector),\n\u001b[0;32m    302\u001b[0m         )\n\u001b[1;32m--> 303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServerSelectionTimeoutError(\n\u001b[0;32m    304\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_message(selector)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Timeout: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms, Topology Description: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m     )\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logged_waiting:\n\u001b[0;32m    308\u001b[0m     _debug_log(\n\u001b[0;32m    309\u001b[0m         _SERVER_SELECTION_LOGGER,\n\u001b[0;32m    310\u001b[0m         message\u001b[38;5;241m=\u001b[39m_ServerSelectionStatusMessage\u001b[38;5;241m.\u001b[39mWAITING,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    316\u001b[0m         remainingTimeMS\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()),\n\u001b[0;32m    317\u001b[0m     )\n",
      "\u001b[1;31mServerSelectionTimeoutError\u001b[0m: localhost:27017: [WinError 10061] No connection could be made because the target machine actively refused it (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6703fa410f3434e93b23e78d, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] No connection could be made because the target machine actively refused it (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "\n",
    "def playlist_table(channel_name):\n",
    "\n",
    "    # Function to convert datetime from ISO 8601 to MySQL format\n",
    "    def convert_to_mysql_datetime(iso_datetime):\n",
    "        try:\n",
    "            return datetime.strptime(iso_datetime, \"%Y-%m-%dT%H:%M:%SZ\").strftime('%Y-%m-%d %H:%M:%S')\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting datetime: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Connect to MySQL\n",
    "    print(\"Connecting to MySQL database...\")\n",
    "    mydb = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        passwd='root',\n",
    "        database='youtube'\n",
    "    )\n",
    "    cursor = mydb.cursor()\n",
    "    print(\"Connected to MySQL database.\")\n",
    "\n",
    "    # Drop the table if it exists\n",
    "    try:\n",
    "        drop_query = '''DROP TABLE IF EXISTS playlists'''\n",
    "        cursor.execute(drop_query)\n",
    "        mydb.commit()\n",
    "        print(\"Dropped existing playlists table (if it existed).\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error dropping table: {e}\")\n",
    "\n",
    "    # Create the table\n",
    "    try:\n",
    "        create_query = '''CREATE TABLE IF NOT EXISTS playlists(\n",
    "                            Playlist_Id VARCHAR(100) PRIMARY KEY,\n",
    "                            Title VARCHAR(100),\n",
    "                            Channel_Id VARCHAR(100),\n",
    "                            Channel_Name VARCHAR(100),\n",
    "                            PublishedAt TIMESTAMP,\n",
    "                            Video_Count INT\n",
    "                        )'''\n",
    "        cursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "        print(\"Playlists table created successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error creating table: {err}\")\n",
    "\n",
    "    # Connect to MongoDB\n",
    "    print(\"Connecting to MongoDB...\")\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    print(\"Connected to MongoDB.\")\n",
    "\n",
    "    # Fetch playlist information from MongoDB\n",
    "    print(\"Fetching playlist information from MongoDB...\")\n",
    "    single_channel_details = []\n",
    "    for ch_data in coll1.find({}, {\"_id\": 0, \"playlist_information\": 1}):\n",
    "        if \"playlist_information\" in ch_data:\n",
    "            single_channel_details.extend(ch_data[\"playlist_information\"])\n",
    "\n",
    "    # Convert the fetched data into a DataFrame\n",
    "    df_single_channel = pd.DataFrame(single_channel_details)\n",
    "\n",
    "    # Convert the datetime strings to MySQL-compatible format\n",
    "    if 'PublishedAt' in df_single_channel.columns:\n",
    "        df_single_channel['PublishedAt'] = df_single_channel['PublishedAt'].apply(convert_to_mysql_datetime)\n",
    "\n",
    "    # Insert DataFrame rows into the MySQL table\n",
    "    insert_query = '''INSERT INTO playlists(\n",
    "                        Playlist_Id,\n",
    "                        Title,\n",
    "                        Channel_Id\n",
    "                        Channel_Name,\n",
    "                        PublishedAt,\n",
    "                        Video_Count\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "    for index, row in df_single_channel.iterrows():\n",
    "        values = (\n",
    "            row['Playlist_Id'],\n",
    "            row['Title'],\n",
    "            row['Channel_Id'],\n",
    "            row['Channel_Name'],\n",
    "            row['PublishedAt'],\n",
    "            row['Video_Count']\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            cursor.execute(insert_query, values)\n",
    "            mydb.commit()\n",
    "            print(f\"Inserted Playlist_Id: {row['Playlist_Id']}\")\n",
    "        except mysql.connector.IntegrityError as ie:\n",
    "            print(f\"IntegrityError: Record with Playlist_Id {row['Playlist_Id']} already exists. Skipping.\")\n",
    "        except mysql.connector.DataError as de:\n",
    "            print(f\"DataError: {de}\")\n",
    "            print(f\"Problematic data: {values}\")\n",
    "            mydb.rollback()\n",
    "        except mysql.connector.Error as err:\n",
    "            print(f\"Error inserting data: {err}\")\n",
    "            mydb.rollback()\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    mydb.close()\n",
    "    print(\"MySQL connection closed.\")\n",
    "\n",
    "# Make sure to call the function\n",
    "playlist_table(\"some_channel_name\")  # Replace with an actual channel name if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 15:22:22.698 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.698 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#single_channel_details= []\n",
    "#db=client[\"Youtube_data\"]\n",
    "#coll1=db[\"channel_details\"]\n",
    "#for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "        #single_channel_details.append(ch_data[\"channel_information\"])\n",
    "#df_single_channel= st.DataFrame(single_channel_details)\n",
    "\n",
    "db = client[\"Youtube_data\"]\n",
    "coll1 = db[\"channel_details\"]\n",
    "\n",
    "# Retrieve channel information\n",
    "try:\n",
    "    single_channel_details = [\n",
    "        ch_data[\"channel_information\"]\n",
    "        for ch_data in coll1.find({}, {\"_id\": 0, \"channel_information\": 1})\n",
    "    ]\n",
    "except Exception as e:\n",
    "    st.error(f\"Error retrieving data: {e}\")\n",
    "    single_channel_details = []\n",
    "\n",
    "# Create DataFrame\n",
    "if single_channel_details:\n",
    "    df_single_channel = pd.DataFrame(single_channel_details)\n",
    "else:\n",
    "    df_single_channel = pd.DataFrame()  # Create an empty DataFrame if no data\n",
    "\n",
    "# Display the DataFrame in Streamlit\n",
    "\n",
    "df_single_channel=st.dataframe(df_single_channel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_channels_table():\n",
    "    single_channel_details= []\n",
    "    db=client[\"Youtube_data\"]\n",
    "    coll1=db[\"channel_details\"]\n",
    "    for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "            single_channel_details.append(ch_data[\"channel_information\"])\n",
    "    df= st.DataFrame(single_channel_details)\n",
    "\n",
    "    return df\n",
    "\n",
    "def show_playlists_table():\n",
    "    single_channel_details = []\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for ch_data in coll1.find({}, {\"_id\": 0, \"playlist_information\": 1}):\n",
    "        single_channel_details.extend(ch_data[\"playlist_information\"])\n",
    "\n",
    "    # Convert the fetched data into a DataFrame\n",
    "    df1 = st.DataFrame(single_channel_details)\n",
    "\n",
    "  \n",
    "\n",
    "    return df1\n",
    "\n",
    "def show_videos_table():\n",
    "    video_data_list = []  # List to hold all videos for all channels\n",
    "    coll1 = db[\"channel_details\"]\n",
    "\n",
    "    for ch_data in coll1.find({}, {\"_id\": 0, \"video_information\": 1}):\n",
    "        # Check if the channel has video information and accumulate all videos\n",
    "        if \"video_information\" in ch_data:\n",
    "            video_data_list.extend(ch_data[\"video_information\"])\n",
    "\n",
    "    # Convert the fetched data into a DataFrame\n",
    "    if video_data_list:\n",
    "        df2 = st.DataFrame(video_data_list)\n",
    "    else:\n",
    "        df2= pd.DataFrame()  # Handle empty data scenario\n",
    "\n",
    "\n",
    "    # Check for and handle dictionary types\n",
    "    def handle_dict(value):\n",
    "        if isinstance(value, dict):\n",
    "            # Extract the default URL if it exists\n",
    "            if 'default' in value and 'url' in value['default']:\n",
    "                return value['default']['url']\n",
    "            else:\n",
    "                return json.dumps(value)  # Fallback to JSON string for complex dicts\n",
    "        return value\n",
    "\n",
    "\n",
    "    return df2\n",
    "\n",
    "def show_comments_table():\n",
    "    single_channel_details = []\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for ch_data in coll1.find({}, {\"_id\": 0, \"comment_information\": 1}):\n",
    "        if \"comment_information\" in ch_data:\n",
    "            single_channel_details.append(ch_data[\"comment_information\"])\n",
    "\n",
    "    # Check if there's data to process\n",
    "    if single_channel_details:\n",
    "        df3 = st.DataFrame(single_channel_details[0])\n",
    "    else:\n",
    "        df3 = st.DataFrame()  # Handle empty data scenario\n",
    "\n",
    "\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 15:22:22.953 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.953 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.968 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.968 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.968 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.968 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.984 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.984 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.984 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.984 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.984 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.999 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.999 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.999 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.999 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.999 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:22.999 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:23.015 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:23.015 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:23.015 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:23.015 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:23.031 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:23.031 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "#streamlit part\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"missing ScriptRunContext!\")\n",
    "\n",
    "\n",
    "with st.sidebar:\n",
    "    st.title(\":red[YOUTUBE DATA HAVERSTING AND WAREHOUSING]\")\n",
    "    st.header(\"Skill Take Away\")\n",
    "    st.caption(\"Python Scripting\")\n",
    "    st.caption(\"Data Collection\")\n",
    "    st.caption(\"MongoDB\")\n",
    "    st.caption(\"API Integration\")\n",
    "    st.caption(\"Data Management using MongoDB and SQL\")\n",
    "\n",
    "channel_id=st.text_input(\"Enter the channel ID\")\n",
    "\n",
    "if st.button(\"collect and store data\"):\n",
    "    ch_ids=[]\n",
    "    db=client[\"Youtube_data\"]\n",
    "    coll1=db[\"channel_details\"]\n",
    "    for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "        ch_ids.append(ch_data[\"channel_information\"][\"Channel_Id\"])\n",
    "\n",
    "    if channel_id in ch_ids:\n",
    "        st.success(\"Channel Details of the given channel id already exists\")\n",
    "\n",
    "    else:\n",
    "        insert=channel_details(channel_id)\n",
    "        st.success(insert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 15:22:23.305 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:23.321 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:23.321 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:23.321 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:23.321 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:23.337 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import streamlit as st\n",
    "#streamlit part\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"missing ScriptRunContext!\")\n",
    "\n",
    "st.title(\"Hello Streamlit\")\n",
    "\n",
    "if st.button(\"Click me\"):\n",
    "    st.write(\"Button clicked!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 15:22:23.719 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:23.719 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:23.719 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:23.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-07 15:22:23.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "1146 (42S02): Table 'youtube.videos' doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMySQLInterfaceError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\mysql\\connector\\connection_cext.py:705\u001b[0m, in \u001b[0;36mCMySQLConnection.cmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[0;32m    704\u001b[0m         query \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 705\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmysql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mMySQLInterfaceError\u001b[0m: Table 'youtube.videos' doesn't exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m question \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. All the videos and the channel name\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     24\u001b[0m     query1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mSELECT title AS videos, channel_names AS channelname FROM videos\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m---> 25\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m cursor\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[0;32m     27\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(t1, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo Title\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChannel Names\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\mysql\\connector\\cursor_cext.py:357\u001b[0m, in \u001b[0;36mCMySQLCursor.execute\u001b[1;34m(self, operation, params, multi)\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ProgrammingError(\n\u001b[0;32m    353\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot all parameters were used in the SQL statement\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    354\u001b[0m             )\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcmd_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_mysql_exception(\n\u001b[0;32m    365\u001b[0m         msg\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mmsg, errno\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39merrno, sqlstate\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39msqlstate\n\u001b[0;32m    366\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\mysql\\connector\\opentelemetry\\context_propagation.py:97\u001b[0m, in \u001b[0;36mwith_context_propagation.<locals>.wrapper\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# pylint: disable=possibly-used-before-assignment\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OTEL_ENABLED \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cnx\u001b[38;5;241m.\u001b[39motel_context_propagation:\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m current_span \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mget_current_span()\n\u001b[0;32m    100\u001b[0m tp_header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\VSCODE\\.venv\\Lib\\site-packages\\mysql\\connector\\connection_cext.py:713\u001b[0m, in \u001b[0;36mCMySQLConnection.cmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmysql\u001b[38;5;241m.\u001b[39mquery(\n\u001b[0;32m    706\u001b[0m         query,\n\u001b[0;32m    707\u001b[0m         raw\u001b[38;5;241m=\u001b[39mraw,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    710\u001b[0m         query_attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_attrs,\n\u001b[0;32m    711\u001b[0m     )\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 713\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_mysql_exception(\n\u001b[0;32m    714\u001b[0m         err\u001b[38;5;241m.\u001b[39merrno, msg\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mmsg, sqlstate\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39msqlstate\n\u001b[0;32m    715\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    717\u001b[0m     addr \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unix_socket \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unix_socket \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_host\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_port\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    719\u001b[0m     )\n",
      "\u001b[1;31mProgrammingError\u001b[0m: 1146 (42S02): Table 'youtube.videos' doesn't exist"
     ]
    }
   ],
   "source": [
    "#SQL Connection\n",
    "mydb = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    passwd='root',\n",
    "    database='youtube'\n",
    ")\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "question = st.selectbox(\"Select your question\", (\n",
    "    \"1. All the videos and the channel name\",\n",
    "    \"2. Channels with most number of videos\",\n",
    "    \"3. 10 most viewed videos\",\n",
    "    \"4. Comments in each video\",\n",
    "    \"5. Videos with highest likes\",\n",
    "    \"6. Likes of all videos\",\n",
    "    \"7. Views of each channel\",\n",
    "    \"8. Videos published in the year 2022\",\n",
    "    \"9. Average duration of all videos in each channel\",\n",
    "    \"10. Videos with highest number of comments\"\n",
    "))\n",
    "\n",
    "if question == \"1. All the videos and the channel name\":\n",
    "    query1 = '''SELECT title AS videos, channel_names AS channelname FROM videos'''\n",
    "    cursor.execute(query1)\n",
    "    t1 = cursor.fetchall()\n",
    "    df = pd.DataFrame(t1, columns=[\"Video Title\", \"Channel Names\"])\n",
    "    st.write(df)\n",
    "\n",
    "elif question == \"2. Channels with most number of videos\":\n",
    "    query2 = '''SELECT channel_names AS channelname, total_videos AS no_videos \n",
    "                FROM channels ORDER BY total_videos DESC'''\n",
    "    cursor.execute(query2)\n",
    "    t2 = cursor.fetchall()\n",
    "    df2 = pd.DataFrame(t2, columns=[\"Channel Names\", \"No of Videos\"])\n",
    "    st.write(df2)\n",
    "\n",
    "elif question == \"3. 10 most viewed videos\":\n",
    "    query3 = '''SELECT views AS views, channel_names AS channelname, title AS videotitle \n",
    "                FROM videos WHERE views IS NOT NULL \n",
    "                ORDER BY views DESC LIMIT 10'''\n",
    "    cursor.execute(query3)\n",
    "    t3 = cursor.fetchall()\n",
    "    df3 = pd.DataFrame(t3, columns=[\"Views\", \"Channel Names\", \"Video Title\"])\n",
    "    st.write(df3)\n",
    "\n",
    "elif question == \"4. Comments in each video\":\n",
    "    query4 = '''SELECT comments AS no_comments, title AS videotitle \n",
    "                FROM videos WHERE comments IS NOT NULL'''\n",
    "    cursor.execute(query4)\n",
    "    t4 = cursor.fetchall()\n",
    "    df4 = pd.DataFrame(t4, columns=[\"No of Comments\", \"Video Title\"])\n",
    "    st.write(df4)\n",
    "\n",
    "elif question == \"5. Videos with highest likes\":\n",
    "    query5 = '''SELECT title AS videotitle, channel_names AS channelname, likes AS likecount \n",
    "                FROM videos WHERE likes IS NOT NULL \n",
    "                ORDER BY likes DESC'''\n",
    "    cursor.execute(query5)\n",
    "    t5 = cursor.fetchall()\n",
    "    df5 = pd.DataFrame(t5, columns=[\"Video Title\", \"Channel Names\", \"Like Count\"])\n",
    "    st.write(df5)\n",
    "\n",
    "elif question == \"6. Likes of all videos\":\n",
    "    query6 = '''SELECT likes AS likecount, title AS videotitle FROM videos'''\n",
    "    cursor.execute(query6)\n",
    "    t6 = cursor.fetchall()\n",
    "    df6 = pd.DataFrame(t6, columns=[\"Like Count\", \"Video Title\"])\n",
    "    st.write(df6)\n",
    "\n",
    "elif question == \"7. Views of each channel\":\n",
    "    query7 = '''SELECT channel_names AS channelname, views AS totalviews FROM channels'''\n",
    "    cursor.execute(query7)\n",
    "    t7 = cursor.fetchall()\n",
    "    df7 = pd.DataFrame(t7, columns=[\"Channel Names\", \"Total Views\"])\n",
    "    st.write(df7)\n",
    "\n",
    "elif question == \"8. Videos published in the year 2022\":\n",
    "    query8 = '''SELECT title AS video_title, published_date AS videorelease, channel_names AS channelname \n",
    "                FROM videos WHERE EXTRACT(YEAR FROM published_date) = 2022'''\n",
    "    cursor.execute(query8)\n",
    "    t8 = cursor.fetchall()\n",
    "    df8 = pd.DataFrame(t8, columns=[\"Video Title\", \"Published Date\", \"Channel Names\"])\n",
    "    st.write(df8)\n",
    "\n",
    "elif question == \"9. Average duration of all videos in each channel\":\n",
    "    query9 = '''SELECT channel_names AS channelname, AVG(duration) AS averageduration \n",
    "                FROM videos GROUP BY channel_names'''\n",
    "    cursor.execute(query9)\n",
    "    t9 = cursor.fetchall()\n",
    "    df9 = pd.DataFrame(t9, columns=[\"Channel Names\", \"Average Duration\"])\n",
    "\n",
    "    # Formatting the average duration if necessary\n",
    "    df9[\"Average Duration\"] = df9[\"Average Duration\"].apply(lambda x: str(x))\n",
    "    st.write(df9)\n",
    "\n",
    "elif question == \"10. Videos with highest number of comments\":\n",
    "    query10 = '''SELECT title AS videotitle, channel_names AS channelname, comments AS comments \n",
    "                 FROM videos WHERE comments IS NOT NULL \n",
    "                 ORDER BY comments DESC'''\n",
    "    cursor.execute(query10)\n",
    "    t10 = cursor.fetchall()\n",
    "    df10 = pd.DataFrame(t10, columns=[\"Video Title\", \"Channel Names\", \"Comments\"])\n",
    "    st.write(df10)\n",
    "\n",
    "# Closing the connection after the queries are done\n",
    "cursor.close()\n",
    "mydb.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 10:28:20.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-16 10:28:20.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-16 10:28:20.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-16 10:28:20.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-16 10:28:20.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-16 10:28:20.721 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-16 10:28:20.721 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-16 10:28:20.721 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-16 10:28:20.721 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-16 10:28:20.739 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-16 10:28:20.742 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-16 10:28:20.742 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-16 10:28:20.742 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-16 10:28:20.742 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-16 10:28:21.033 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-16 10:28:21.041 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "# Fetching all channel names from MongoDB\n",
    "all_channels = []\n",
    "coll1 = db[\"channel_details\"]\n",
    "for ch_data in coll1.find({}, {\"_id\": 0, \"channel_information\": 1}):\n",
    "    try:\n",
    "        all_channels.append(ch_data[\"channel_information\"][\"Channel_Names\"])\n",
    "    except KeyError:\n",
    "        st.error(\"Error: 'Channel_Names' key not found in channel information\")\n",
    "\n",
    "# Streamlit selectbox to choose a channel\n",
    "unique_channel = st.selectbox(\"Select the Channel\", all_channels)\n",
    "\n",
    "# Migrate to SQL if button is clicked\n",
    "if st.button(\"Migrate to Sql\"):\n",
    "    try:\n",
    "        Table = tables(unique_channel)  # Make sure `tables` is defined\n",
    "        st.success(f\"Migration successful for {unique_channel}\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error during migration: {str(e)}\")\n",
    "\n",
    "# Show different tables based on user selection\n",
    "show_table = st.radio(\"SELECT THE TABLE FOR VIEW\", (\"CHANNELS\", \"PLAYLISTS\", \"VIDEOS\", \"COMMENTS\"))\n",
    "\n",
    "if show_table == \"CHANNELS\":\n",
    "    try:\n",
    "        show_channels_table()  # Ensure this function is defined\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error displaying channels table: {str(e)}\")\n",
    "\n",
    "elif show_table == \"PLAYLISTS\":\n",
    "    try:\n",
    "        show_playlists_table()  # Ensure this function is defined\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error displaying playlists table: {str(e)}\")\n",
    "\n",
    "elif show_table == \"VIDEOS\":\n",
    "    try:\n",
    "        show_videos_table()  # Ensure this function is defined\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error displaying videos table: {str(e)}\")\n",
    "\n",
    "elif show_table == \"COMMENTS\":\n",
    "    try:\n",
    "        show_comments_table()  # Ensure this function is defined\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error displaying comments table: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
